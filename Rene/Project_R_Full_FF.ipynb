{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innocent-desperate",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-lambda",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selective-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-slovakia",
   "metadata": {},
   "source": [
    "## 1. Classification, weight sharing, auxiliary losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import generate_pair_sets\n",
    "N = 1000\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "underlying-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "therapeutic-fellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 9],\n",
       "        [1, 8],\n",
       "        [5, 3],\n",
       "        ...,\n",
       "        [2, 7],\n",
       "        [2, 0],\n",
       "        [8, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-indonesia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-endorsement",
   "metadata": {},
   "source": [
    "## 2. Mini deep-learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "starting-quantum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x24210e722c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from torch import empty\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stretch-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disk_set(N):\n",
    "    \n",
    "    # Generate train sets of 2 uniform distributions on [0,1]x[0,1]\n",
    "    train_input = torch.empty(N, 2).uniform_(0, 1)\n",
    "    test_input = torch.empty(N, 2).uniform_(0, 1)\n",
    "    \n",
    "    recenter = torch.tensor([0.5, 0.5]) # to act as if the train data was centered around 0, to ease the following computation\n",
    "    \n",
    "    # Generate the target tensors filled with 1 if datapoint is inside of specific circle\n",
    "    train_target = (-(train_input - recenter).pow(2).sum(1).sqrt().sub(1 / math.sqrt(2 * math.pi))).sign().add(1).div(2).int()\n",
    "    test_target = (-(train_input - recenter).pow(2).sum(1).sqrt().sub(1 / math.sqrt(2 * math.pi))).sign().add(1).div(2).int()\n",
    "    \n",
    "    return train_input, test_input, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "double-castle",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3001, 0.3820],\n",
       "         [0.4924, 0.3364],\n",
       "         [0.7606, 0.4009],\n",
       "         ...,\n",
       "         [0.1031, 0.2530],\n",
       "         [0.1492, 0.7535],\n",
       "         [0.9453, 0.8437]]),\n",
       " tensor([[0.2621, 0.4073],\n",
       "         [0.8742, 0.5634],\n",
       "         [0.0227, 0.9914],\n",
       "         ...,\n",
       "         [0.9823, 0.0819],\n",
       "         [0.4692, 0.0556],\n",
       "         [0.8813, 0.7483]]),\n",
       " tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "         0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "         1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "         1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "         1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "         0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "         1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "         0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "         1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "         1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "         0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=torch.int32),\n",
       " tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "         0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "         1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "         1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "         1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "         0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "         1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "         0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "         1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "         1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "         0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=torch.int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input, test_input, train_target, test_target = generate_disk_set(N)\n",
    "train_input, test_input, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "younger-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    '''\n",
    "    Compute forward pass from an input tensor and return a tensor\n",
    "    or a tuple of tensors as output\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        '''\n",
    "        should get as input a tensor or a tuple of tensors containing the \n",
    "        gradient of the loss with respect to the module’s output, accumulate \n",
    "        the gradient wrt the parameters, and return a tensor or a tuple of\n",
    "        tensors containing the gradient of the loss wrt the module’s input.\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def params(self):\n",
    "        '''\n",
    "        param should return a list of pairs, each composed of a parameter tensor, and a gradient tensor\n",
    "        of same size. This list should be empty for parameterless modules (e.g. ReLU).\n",
    "\n",
    "        '''\n",
    "        return []\n",
    "        \n",
    "    def reset_params(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-today",
   "metadata": {},
   "source": [
    "### 1. Linear module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quality-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.init import xavier_normal_, xavier_normal\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(Linear, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        self.epsilon = 1e-3\n",
    "        self.x = 0\n",
    "\n",
    "        # Initialize weights\n",
    "        self.w = xavier_normal_(torch.empty(self.dim_out, self.dim_in))\n",
    "        self.b = torch.empty(self.dim_out).normal_(0, self.epsilon)\n",
    "\n",
    "        # Initialize gradient\n",
    "        self.dl_dw = torch.empty(self.w.size())\n",
    "        self.dl_db = torch.empty(self.b.size())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.x.mm(self.w.t()) + self.b\n",
    "\n",
    "\n",
    "    def backward(self, grad):\n",
    "        ds_dx = self.w.t()\n",
    "\n",
    "        # do the same for every batch (batch dim becomes 1)\n",
    "        dl_dx = ds_dx @ grad.t()\n",
    "\n",
    "        # put batch dim back to 0\n",
    "        dl_dx = dl_dx.t()\n",
    "\n",
    "        # sum over all the outer product between (grad_1 * x_1^T) (_1 denotes not using mini-batches)\n",
    "        self.dl_dw.add_(grad.t() @ self.x)\n",
    "\n",
    "        # sum over the batch\n",
    "        self.dl_db.add_(grad.sum(0))\n",
    "\n",
    "        return dl_dx\n",
    "        \n",
    "    def params(self):\n",
    "        return [(self.w, self.b), (self.dl_dw, self.dl_db)]\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        self.w = self.w - eta * self.dl_dw\n",
    "        self.b = self.b - eta * self.dl_db\n",
    "        \n",
    "    def reset_gradient(self):\n",
    "        self.dl_dw.zero_()\n",
    "        self.dl_db.zero_()\n",
    "\n",
    "    def reset_params(self):\n",
    "        # Initialize weights\n",
    "        xavier_normal_(self.w)\n",
    "        self.b.normal_(0, self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-barbados",
   "metadata": {},
   "source": [
    "### 2. ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "disturbed-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def dReLU(x):\n",
    "    s = x.clone()\n",
    "    s[x>0] = 1\n",
    "    s[x<=0] = 0\n",
    "    return s\n",
    "\n",
    "\n",
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x.clamp(min=0)\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        #ds_dx = dReLU(self.x)\n",
    "        ds_dx = (torch.sign(self.x) + 1)/2\n",
    "        dl_dx = ds_dx*grad\n",
    "        return dl_dx\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        return\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-aquatic",
   "metadata": {},
   "source": [
    "### 3. Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mechanical-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super(Tanh, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x.tanh()\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        ds_dx = 4 * (self.x.exp() + self.x.mul(-1).exp()).pow(-2)\n",
    "        dl_dx = ds_dx*grad\n",
    "        return dl_dx\n",
    "        \n",
    "    def params(self):\n",
    "        return []\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        return\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-supplement",
   "metadata": {},
   "source": [
    "### 4. Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pleased-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Module):\n",
    "    def __init__(self, *modules):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.module_lst = []\n",
    "        for module in modules:\n",
    "            self.module_lst.append(module)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for module in self.module_lst:\n",
    "            x = module.forward(x)\n",
    "        return x\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        for module in reversed(self.module_lst):\n",
    "            grad = module.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        for module in self.module_lst:\n",
    "            module.update_params(eta)\n",
    "            \n",
    "    def params(self):\n",
    "        lst = []\n",
    "        for module in self.module_lst:\n",
    "            lst.append(module.params())\n",
    "        return lst\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        for module in self.module_lst:\n",
    "            module.reset_gradient()\n",
    "        return\n",
    "    \n",
    "    def reset_params(self):\n",
    "        for module in self.module_lst:\n",
    "            module.reset_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-termination",
   "metadata": {},
   "source": [
    "### 5. Loss (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dramatic-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, v, t):\n",
    "        return (v - t).pow(2).sum()\n",
    "    \n",
    "    def backward(self, v, t):\n",
    "        return 2 * (v - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-iceland",
   "metadata": {},
   "source": [
    "### 6. Internet SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "handled-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self,parameters):\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def step(self): \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def zeroGrad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = 0.\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self,parameters,lr=.001,weight_decay=0.0,momentum = .9):\n",
    "        super().__init__(parameters)\n",
    "        self.lr           = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum     = momentum\n",
    "        self.velocity     = []\n",
    "        for p in parameters:\n",
    "            self.velocity.append(np.zeros_like(p.grad))\n",
    "\n",
    "    def step(self):\n",
    "        for p,v in zip(self.parameters,self.velocity):\n",
    "            v = self.momentum*v+p.grad+self.weight_decay*p.data\n",
    "            p.data=p.data-self.lr*v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-frank",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-gnome",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "matched-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(256, nb_hidden)\n",
    "        self.fc2 = Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dimensional-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "upper-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size = 10, nb_epochs = 100):\n",
    "    criterion = MSELoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "\n",
    "        print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "suspended-mother",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Net' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-557e3c333793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmini_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-0ed672bd06b3>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_target, mini_batch_size, nb_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0macc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Net' object is not callable"
     ]
    }
   ],
   "source": [
    "model = Net(200)\n",
    "mini_batch_size = 100\n",
    "train_model(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "capable-andorra",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-8d483cf05337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0moptim\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Net' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "batch_size        = 20\n",
    "num_epochs        = 200\n",
    "samples_per_class = 100\n",
    "num_classes       = 3\n",
    "hidden_units      = 100\n",
    "\n",
    "model             = Net(100)\n",
    "optim   = SGD(model.parameters,lr=1.0,weight_decay=0.001,momentum=.9)\n",
    "loss_fn = MSELoss()\n",
    "model.fit(train_input,train_target,batch_size,num_epochs,optim,loss_fn)\n",
    "predicted_labels = np.argmax(model.predict(data),axis=1)\n",
    "accuracy         = np.sum(predicted_labels==target)/len(target)\n",
    "print(\"Model Accuracy = {}\".format(accuracy))\n",
    "utilities.plot2DDataWithDecisionBoundary(data,target,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-chester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reserved-coordinator",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# OneNote and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "personal-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0126, 0.0244]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# MLP with 10 dimension input, 2 dimension output, ReLu activation and 2 hidden layers of dimension 100 and 50 :\n",
    "\n",
    "nb_hidden = 25\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(train_input.size(0),nb_hidden), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden, nb_hidden), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden, nb_hidden), nn.ReLU(),\n",
    "    nn.Linear(nb_hidden,2)\n",
    ")\n",
    "output = model(train_input[:,0])\n",
    "print(output, output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "For any model of reasonable complexity, the best is to write a sub-class of torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "pressing-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "nb_hidden = 25\n",
    "train_input, test_input, train_target, test_target = generate_disk_set(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "pregnant-attachment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4474, 0.1293, 0.3799, 0.9915, 0.3407, 0.2672, 0.2204, 0.4320, 0.9817,\n",
       "        0.9715, 0.3266, 0.3897, 0.2064, 0.9942, 0.0016, 0.3661, 0.9314, 0.5677,\n",
       "        0.8934, 0.4375, 0.5778, 0.0275, 0.4904, 0.4365, 0.6211, 0.7106, 0.6118,\n",
       "        0.0729, 0.5501, 0.3222, 0.4279, 0.0826, 0.0834, 0.8889, 0.5114, 0.9144,\n",
       "        0.9046, 0.6023, 0.4327, 0.1574, 0.4418, 0.1041, 0.4096, 0.1024, 0.5083,\n",
       "        0.1955, 0.5527, 0.3064, 0.3274, 0.4981, 0.0486, 0.9130, 0.7728, 0.5100,\n",
       "        0.1335, 0.0131, 0.3708, 0.2610, 0.2100, 0.5865, 0.8330, 0.2257, 0.9406,\n",
       "        0.6698, 0.2257, 0.7610, 0.0579, 0.6792, 0.6793, 0.7769, 0.4474, 0.8501,\n",
       "        0.0397, 0.1228, 0.8479, 0.7594, 0.1201, 0.3619, 0.6985, 0.3740, 0.1334,\n",
       "        0.0299, 0.8139, 0.6408, 0.1183, 0.7721, 0.8264, 0.5864, 0.7392, 0.3238,\n",
       "        0.4670, 0.0569, 0.2674, 0.9871, 0.1755, 0.1720, 0.0281, 0.8237, 0.9125,\n",
       "        0.5453, 0.1243, 0.5424, 0.4292, 0.2261, 0.3241, 0.3811, 0.3366, 0.7102,\n",
       "        0.3545, 0.1935, 0.1812, 0.3359, 0.3401, 0.5656, 0.1912, 0.7260, 0.1462,\n",
       "        0.7361, 0.9299, 0.5695, 0.6988, 0.4935, 0.4796, 0.4083, 0.8752, 0.2406,\n",
       "        0.4045, 0.9005, 0.4918, 0.7055, 0.7150, 0.7964, 0.5301, 0.3047, 0.3848,\n",
       "        0.3334, 0.7253, 0.8667, 0.4587, 0.1212, 0.5315, 0.4965, 0.0662, 0.0546,\n",
       "        0.3364, 0.7348, 0.5182, 0.4100, 0.0777, 0.3975, 0.6261, 0.4139, 0.1629,\n",
       "        0.2255, 0.9752, 0.8759, 0.9352, 0.2564, 0.6522, 0.5423, 0.9166, 0.8359,\n",
       "        0.3321, 0.8353, 0.6436, 0.8544, 0.3816, 0.4663, 0.3825, 0.9013, 0.4916,\n",
       "        0.8173, 0.2742, 0.5704, 0.0363, 0.3730, 0.0444, 0.6759, 0.7516, 0.5440,\n",
       "        0.4047, 0.0486, 0.3861, 0.3219, 0.2944, 0.1294, 0.9965, 0.1968, 0.0508,\n",
       "        0.3073, 0.1815, 0.9675, 0.2636, 0.2604, 0.6958, 0.0477, 0.4198, 0.3830,\n",
       "        0.6931, 0.3019])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.view(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
