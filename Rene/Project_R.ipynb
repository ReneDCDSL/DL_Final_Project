{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innocent-desperate",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-lambda",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selective-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-slovakia",
   "metadata": {},
   "source": [
    "## 1. Classification, weight sharing, auxiliary losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minute-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import generate_pair_sets\n",
    "N = 1000\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "underlying-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "therapeutic-fellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 9],\n",
       "        [1, 8],\n",
       "        [5, 3],\n",
       "        ...,\n",
       "        [2, 7],\n",
       "        [2, 0],\n",
       "        [8, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-indonesia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-endorsement",
   "metadata": {},
   "source": [
    "## 2. Mini deep-learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "starting-quantum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1e696218088>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from torch import empty\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-focus",
   "metadata": {},
   "source": [
    "You should implement at least the modules Linear (fully connected layer), ReLU, Tanh, Sequential\n",
    "to combine several modules in basic sequential structure, and LossMSE to compute the MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_set(N):\n",
    "    train_input = torch.empty\n",
    "    train_target =\n",
    "    test_input =\n",
    "    test_target =    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "stretch-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disk_set(N):\n",
    "    \n",
    "    # Generate train sets of 2 uniform distributions on [0,1]x[0,1]\n",
    "    train_input = torch.empty(N, 2).uniform_(0, 1)\n",
    "    test_input = torch.empty(N, 2).uniform_(0, 1)\n",
    "    \n",
    "    recenter = torch.tensor([0.5, 0.5]) # to act as if the train data was centered around 0, to ease the following computation\n",
    "    \n",
    "    # Generate the target tensors filled with 1 if datapoint is inside of specific circle\n",
    "    train_target = (-(train_input - recenter).pow(2).sum(1).sqrt().sub(1 / math.sqrt(2 * math.pi))).sign().add(1).div(2).int()\n",
    "    test_target = (-(train_input - recenter).pow(2).sum(1).sqrt().sub(1 / math.sqrt(2 * math.pi))).sign().add(1).div(2).int()\n",
    "    \n",
    "    return train_input, test_input, train_target,test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "sorted-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.empty(N, 2).uniform_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "double-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6239, 0.4620],\n",
       "         [0.4435, 0.2048],\n",
       "         [0.6534, 0.1526],\n",
       "         ...,\n",
       "         [0.9025, 0.1418],\n",
       "         [0.7172, 0.2822],\n",
       "         [0.8464, 0.6788]]),\n",
       " tensor([[0.9338, 0.6325],\n",
       "         [0.0889, 0.7811],\n",
       "         [0.3600, 0.9220],\n",
       "         ...,\n",
       "         [0.0147, 0.8352],\n",
       "         [0.4646, 0.7292],\n",
       "         [0.6887, 0.7567]]),\n",
       " tensor([1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "         1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "         1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "         0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "         1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1], dtype=torch.int32),\n",
       " tensor([1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "         1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "         1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "         0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "         1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "         1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1], dtype=torch.int32))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = generate_disc_set(N)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "behavioral-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1185, 0.8120],\n",
       "        [0.1680, 0.3330],\n",
       "        [0.6334, 0.8082],\n",
       "        ...,\n",
       "        [0.0145, 0.3900],\n",
       "        [0.5582, 0.4001],\n",
       "        [0.7525, 0.8462]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty(N, 2).uniform_(0, 1).pow(2).sum(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-killer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-czech",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module (object):\n",
    "    \n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward (self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param (self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \"\"\"\n",
    "    Linear layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        self.weights = torch.empty((in_feats, out_feats))\n",
    "        self.bias = torch.empty((1, out_feats))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        output = x @ self.weights + self.bias\n",
    "        return output\n",
    "\n",
    "    def backward(self, dy):\n",
    "        pass\n",
    "\n",
    "    def params(self):\n",
    "        return [self.weights, self.bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2020/09/implementing-deep-learning-library-scratch-python.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Linear(Function):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.weights = Tensor((in_dim,out_dim))\n",
    "        self.bias    = Tensor((1, out_dim))\n",
    "        self.type = 'linear'\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = np.dot(x,self.weights.data)+self.bias.data\n",
    "        self.input = x \n",
    "        return output\n",
    "\n",
    "    def backward(self,d_y):\n",
    "        self.weights.grad += np.dot(self.input.T,d_y)\n",
    "        self.bias.grad    += np.sum(d_y,axis=0,keepdims=True)\n",
    "        grad_input         = np.dot(d_y,self.weights.data.T)\n",
    "        return grad_input\n",
    "\n",
    "    def getParams(self):\n",
    "        return [self.weights,self.bias]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class SGD(Optimizer):\n",
    "    def __init__(self,parameters,lr=.001,weight_decay=0.0,momentum = .9):\n",
    "        super().__init__(parameters)\n",
    "        self.lr           = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum     = momentum\n",
    "        self.velocity     = []\n",
    "        for p in parameters:\n",
    "            self.velocity.append(np.zeros_like(p.grad))\n",
    "\n",
    "    def step(self):\n",
    "        for p,v in zip(self.parameters,self.velocity):\n",
    "            v = self.momentum*v+p.grad+self.weight_decay*p.data\n",
    "            p.data=p.data-self.lr*v\n",
    "            \n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.computation_graph = []\n",
    "        self.parameters        = []\n",
    "\n",
    "    def add(self,layer):\n",
    "        self.computation_graph.append(layer)\n",
    "        self.parameters+=layer.getParams()\n",
    "\n",
    "    def __innitializeNetwork(self):\n",
    "        for f in self.computation_graph:\n",
    "            if f.type=='linear':\n",
    "                weights,bias = f.getParams()\n",
    "                weights.data = .01*np.random.randn(weights.data.shape[0],weights.data.shape[1])\n",
    "                bias.data    = 0.\n",
    "\n",
    "    def fit(self,data,target,batch_size,num_epochs,optimizer,loss_fn):\n",
    "        loss_history = []\n",
    "        self.__innitializeNetwork()\n",
    "        data_gen = DataGenerator(data,target,batch_size)\n",
    "        itr = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for X,Y in data_gen:\n",
    "                optimizer.zeroGrad()\n",
    "                for f in self.computation_graph: X=f.forward(X)\n",
    "                loss = loss_fn.forward(X,Y)\n",
    "                grad = loss_fn.backward()\n",
    "                for f in self.computation_graph[::-1]: grad = f.backward(grad) \n",
    "                loss_history+=[loss]\n",
    "                print(\"Loss at epoch = {} and iteration = {}: {}\".format(epoch,itr,loss_history[-1]))\n",
    "                itr+=1\n",
    "                optimizer.step()\n",
    "        \n",
    "        return loss_history\n",
    "    \n",
    "    def predict(self,data):\n",
    "        X = data\n",
    "        for f in self.computation_graph: X = f.forward(X)\n",
    "        return X\n",
    "\n",
    "import dl_numpy as DL\n",
    "import utilities\n",
    "\n",
    "batch_size        = 20\n",
    "num_epochs        = 200\n",
    "samples_per_class = 100\n",
    "num_classes       = 3\n",
    "hidden_units      = 100\n",
    "data,target       = utilities.genSpiralData(samples_per_class,num_classes)\n",
    "model             = utilities.Model()\n",
    "model.add(DL.Linear(2,hidden_units))\n",
    "model.add(DL.ReLU())\n",
    "model.add(DL.Linear(hidden_units,num_classes))\n",
    "optim   = DL.SGD(model.parameters,lr=1.0,weight_decay=0.001,momentum=.9)\n",
    "loss_fn = DL.SoftmaxWithLoss()\n",
    "model.fit(data,target,batch_size,num_epochs,optim,loss_fn)\n",
    "predicted_labels = np.argmax(model.predict(data),axis=1)\n",
    "accuracy         = np.sum(predicted_labels==target)/len(target)\n",
    "print(\"Model Accuracy = {}\".format(accuracy))\n",
    "utilities.plot2DDataWithDecisionBoundary(data,target,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-words",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-roads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
