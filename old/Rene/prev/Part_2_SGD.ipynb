{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quality-breeding",
   "metadata": {},
   "source": [
    "# Mini deep-learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convertible-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1a916f2a3c8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import empty\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-possibility",
   "metadata": {},
   "source": [
    "### Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "precious-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def params(self):\n",
    "        return []\n",
    "        \n",
    "    def reset_params(self):\n",
    "        return\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "from torch.nn.init import xavier_normal_, xavier_normal\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(Linear, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        self.epsilon = 1e-3\n",
    "        self.x = 0\n",
    "\n",
    "        # Initialize weights\n",
    "        self.w = xavier_normal_(torch.empty(self.dim_out, self.dim_in))\n",
    "        self.b = torch.empty(self.dim_out).normal_(0, self.epsilon)\n",
    "\n",
    "        # Initialize gradient\n",
    "        self.dl_dw = torch.empty(self.w.size())\n",
    "        self.dl_db = torch.empty(self.b.size())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.x.mm(self.w.t()) + self.b\n",
    "\n",
    "\n",
    "    def backward(self, grad):\n",
    "        ds_dx = self.w.t()\n",
    "\n",
    "        # do the same for every batch (batch dim becomes 1)\n",
    "        dl_dx = ds_dx @ grad.t()\n",
    "\n",
    "        # put batch dim back to 0\n",
    "        dl_dx = dl_dx.t()\n",
    "\n",
    "        # sum over all the outer product between (grad_1 * x_1^T) (_1 denotes not using mini-batches)\n",
    "        self.dl_dw.add_(grad.t() @ self.x)\n",
    "\n",
    "        # sum over the batch\n",
    "        self.dl_db.add_(grad.sum(0))\n",
    "\n",
    "        return dl_dx\n",
    "        \n",
    "    def params(self):\n",
    "        return [(self.w, self.b), (self.dl_dw, self.dl_db)]\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        self.w = self.w - eta * self.dl_dw\n",
    "        self.b = self.b - eta * self.dl_db\n",
    "        \n",
    "    def reset_gradient(self):\n",
    "        self.dl_dw.zero_()\n",
    "        self.dl_db.zero_()\n",
    "\n",
    "    def reset_params(self):\n",
    "        # Initialize weights\n",
    "        xavier_normal_(self.w)\n",
    "        self.b.normal_(0, self.epsilon)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "class Sequential(Module):\n",
    "    def __init__(self, *modules):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.module_lst = []\n",
    "        for module in modules:\n",
    "            self.module_lst.append(module)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for module in self.module_lst:\n",
    "            x = module.forward(x)\n",
    "        return x\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        for module in reversed(self.module_lst):\n",
    "            grad = module.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        for module in self.module_lst:\n",
    "            module.update_params(eta)\n",
    "            \n",
    "    def params(self):\n",
    "        lst = []\n",
    "        for module in self.module_lst:\n",
    "            lst.append(module.params())\n",
    "        return lst\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        for module in self.module_lst:\n",
    "            module.reset_gradient()\n",
    "        return\n",
    "    \n",
    "    def reset_params(self):\n",
    "        for module in self.module_lst:\n",
    "            module.reset_params()\n",
    "        return    \n",
    "            \n",
    "            \n",
    "###########################################################################################################\n",
    "\n",
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x.clamp(min=0)\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        ds_dx = (torch.sign(self.x) + 1) / 2\n",
    "        dl_dx = ds_dx * grad\n",
    "        return dl_dx\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        return\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        return\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super(Tanh, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x.tanh()\n",
    "        \n",
    "    def backward(self, grad):\n",
    "        ds_dx = 4 * (self.x.exp() + self.x.mul(-1).exp()).pow(-2)\n",
    "        dl_dx = ds_dx*grad\n",
    "        return dl_dx\n",
    "        \n",
    "    def params(self):\n",
    "        return []\n",
    "    \n",
    "    def update_params(self, eta):\n",
    "        return\n",
    "    \n",
    "    def reset_gradient(self):\n",
    "        return\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "class MSELoss(Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, v, t):\n",
    "        return (v - t).pow(2).sum()\n",
    "    \n",
    "    def backward(self, v, t):\n",
    "        return 2 * (v - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe no need to implement ourselves (no written in the project pdf at least, but reward for 'originality')\n",
    "# From https://towardsdatascience.com/on-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8\n",
    "\n",
    "class Optimizer(object):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def step(self): \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def zeroGrad(self):\n",
    "        for p in self.params:\n",
    "            p.grad = 0.\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr = .001, momentum = .999):\n",
    "        super().__init__(params)\n",
    "        self.lr           = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum     = momentum\n",
    "        self.velocity     = []\n",
    "        for p in params:\n",
    "            self.velocity.append(np.zeros_like(p.grad))\n",
    "\n",
    "    def step(self):\n",
    "        for p,v in zip(self.params, self.velocity):\n",
    "            v = self.momentum * v + p.grad \n",
    "            p.data = p.data-self.lr * v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-drama",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "scenic-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disk_set(N=1000):\n",
    "    \n",
    "    # Generate train sets of 2 uniform distributions on [0,1]x[0,1]\n",
    "    input = torch.empty(N, 2).uniform_(0, 1)\n",
    "    \n",
    "    recenter = torch.tensor([0.5, 0.5]) # to act as if the train data was centered around 0, to ease the following computation\n",
    "    \n",
    "    # Generate the target tensors filled with 1 if datapoint is inside of specific circle\n",
    "    target = (-(input - recenter).pow(2).sum(1).sqrt().sub(1 / math.sqrt(2 * math.pi))).sign().add(1).div(2).long()\n",
    "    \n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "center-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "train_input, train_target = generate_disk_set(N)\n",
    "test_input, test_target = generate_disk_set(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "announced-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    # creating the circle in the middle of the points\n",
    "    axis = torch.FloatTensor(1,2).uniform_(0.5,0.5)\n",
    "    r = 1/((2*math.pi)**0.5)\n",
    "\n",
    "    train_input   =  torch.FloatTensor(nb, 2).uniform_(0,1)\n",
    "    train_target  =  torch.FloatTensor(nb, 2)\n",
    "    train_mask    =  torch.FloatTensor(nb, 1)\n",
    "    test_input    =  torch.FloatTensor(nb, 2).uniform_(0,1)\n",
    "    test_target   =  torch.FloatTensor(nb, 2)\n",
    "    test_mask     =  torch.FloatTensor(nb, 1)\n",
    "\n",
    "    for i in range(0, len(train_input)):\n",
    "        a = abs((train_input[i] - axis).pow(2).sum(1).view(-1).pow(0.5))\n",
    "        b = abs((test_input[i]  - axis).pow(2).sum(1).view(-1).pow(0.5))\n",
    "\n",
    "        if a < r:\n",
    "            train_target[i][0] = 0\n",
    "            train_target[i][1] = 1\n",
    "            train_mask[i]      = 1\n",
    "        else:\n",
    "            train_target[i][0] = 1\n",
    "            train_target[i][1] = 0\n",
    "            train_mask[i]      = 0\n",
    "\n",
    "        if b < r:\n",
    "            test_target[i][0] = 0\n",
    "            test_target[i][1] = 1\n",
    "            test_mask[i]      = 1\n",
    "        else:\n",
    "            test_target[i][0] = 1\n",
    "            test_target[i][1] = 0\n",
    "            test_mask[i]      = 0\n",
    "\n",
    "    return train_input, train_target, test_input, test_target, test_mask, train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "raised-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, test_input, test_target, test_mask, train_mask = generate_disc_set(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "changing-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-contractor",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automated-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of constants\n",
    "input_units = 2\n",
    "output_units = 2\n",
    "hidden_units = 25\n",
    "nb_epochs = 1000\n",
    "mini_batch_size = 100\n",
    "eta = 1e-3\n",
    "\n",
    "model_1 = Sequential(\n",
    "            Linear(input_units, hidden_units),\n",
    "            ReLU(),\n",
    "            Linear(hidden_units, hidden_units),\n",
    "            ReLU(),\n",
    "            Linear(hidden_units, output_units),\n",
    "            ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-malta",
   "metadata": {},
   "source": [
    "### Fonction train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "valuable-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, nb_epochs, mini_batch_size, criterion=MSELoss(), eta=1e-3):\n",
    "    model.reset_params()\n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            \n",
    "            # forward pass\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion.forward(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            # backward pass\n",
    "            model.reset_gradient()\n",
    "            model.backward(criterion.backward(output, train_target.narrow(0, b, mini_batch_size)))\n",
    "            model.update_params(eta)\n",
    "            \n",
    "        output = model.forward(train_input)\n",
    "        pred = output.max(1)[1]\n",
    "        error = (pred != train_mask.view(1,-1)).sum()\n",
    "        error_rate = (error/train_input.size(0)) * 100\n",
    "\n",
    "        print(\"epoch: {}, loss: {:.02f}, error {:.02f}% \".format(e, sum_loss, error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ready-ultimate",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0faaf937533d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-a740c62df8b6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_target, nb_epochs, mini_batch_size, criterion, eta)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1b5a3d14d562>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, v, t)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_model(model_1, train_input, train_target, nb_epochs, mini_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-agreement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-future",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sudden-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.narrow(0, 1, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "structured-engagement",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0223],\n",
       "        [-0.1567],\n",
       "        [-0.1203],\n",
       "        [-0.1463],\n",
       "        [-0.1464],\n",
       "        [-0.0544],\n",
       "        [-0.1133],\n",
       "        [-0.0037],\n",
       "        [-0.1420],\n",
       "        [-0.1136],\n",
       "        [-0.0576],\n",
       "        [-0.0474],\n",
       "        [-0.0663],\n",
       "        [-0.1211],\n",
       "        [-0.0402],\n",
       "        [-0.0281],\n",
       "        [-0.0350],\n",
       "        [-0.0528],\n",
       "        [-0.1044],\n",
       "        [-0.0794],\n",
       "        [-0.0733],\n",
       "        [-0.0375],\n",
       "        [-0.1585],\n",
       "        [-0.0345],\n",
       "        [-0.0866],\n",
       "        [-0.0672],\n",
       "        [-0.0220],\n",
       "        [-0.1349],\n",
       "        [-0.1387],\n",
       "        [-0.0860],\n",
       "        [-0.0209],\n",
       "        [-0.1067],\n",
       "        [-0.0811],\n",
       "        [-0.1210],\n",
       "        [-0.0131],\n",
       "        [-0.0754],\n",
       "        [-0.0578],\n",
       "        [-0.0072],\n",
       "        [-0.1040],\n",
       "        [-0.1157],\n",
       "        [-0.0236],\n",
       "        [-0.0372],\n",
       "        [-0.0154],\n",
       "        [-0.1044],\n",
       "        [-0.0253],\n",
       "        [-0.0078],\n",
       "        [-0.1118],\n",
       "        [-0.1328],\n",
       "        [-0.1306],\n",
       "        [-0.0800],\n",
       "        [-0.0568],\n",
       "        [-0.0542],\n",
       "        [-0.0604],\n",
       "        [-0.0845],\n",
       "        [-0.0271],\n",
       "        [-0.0837],\n",
       "        [-0.0497],\n",
       "        [-0.1115],\n",
       "        [-0.1187],\n",
       "        [-0.0983],\n",
       "        [-0.0687],\n",
       "        [-0.1399],\n",
       "        [-0.1311],\n",
       "        [-0.0739],\n",
       "        [-0.1539],\n",
       "        [-0.1594],\n",
       "        [-0.1302],\n",
       "        [-0.0756],\n",
       "        [-0.0257],\n",
       "        [-0.0274],\n",
       "        [-0.0816],\n",
       "        [-0.1070],\n",
       "        [-0.0889],\n",
       "        [-0.1304],\n",
       "        [-0.1365],\n",
       "        [-0.0183],\n",
       "        [-0.1461],\n",
       "        [-0.0648],\n",
       "        [-0.0959],\n",
       "        [-0.0363],\n",
       "        [-0.0248],\n",
       "        [-0.0316],\n",
       "        [-0.0796],\n",
       "        [-0.0913],\n",
       "        [-0.1121],\n",
       "        [-0.0275],\n",
       "        [-0.0766],\n",
       "        [-0.0355],\n",
       "        [-0.1348],\n",
       "        [-0.0719],\n",
       "        [-0.0764],\n",
       "        [-0.1071],\n",
       "        [-0.0229],\n",
       "        [-0.1647],\n",
       "        [-0.0584],\n",
       "        [-0.0718],\n",
       "        [-0.1270],\n",
       "        [-0.0694],\n",
       "        [-0.0475],\n",
       "        [-0.1030]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.forward(train_input.narrow(0, 1, mini_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "sapphire-heating",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0000, 0.0000, 0.0139, 0.0047, 0.0153, 0.0082, 0.0188, 0.0108, 0.0000,\n",
       "        0.0151, 0.0142, 0.0166, 0.0000, 0.0000, 0.0000, 0.0123, 0.0033, 0.0151,\n",
       "        0.0101, 0.0153, 0.0111, 0.0000, 0.0053, 0.0144, 0.0114, 0.0137, 0.0162,\n",
       "        0.0086, 0.0120, 0.0094, 0.0000, 0.0127, 0.0085, 0.0093, 0.0000, 0.0000,\n",
       "        0.0158, 0.0043, 0.0087, 0.0096, 0.0036, 0.0050, 0.0000, 0.0000, 0.0031,\n",
       "        0.0139, 0.0039, 0.0036, 0.0112, 0.0184, 0.0000, 0.0000, 0.0016, 0.0000,\n",
       "        0.0160, 0.0000, 0.0000, 0.0148, 0.0126, 0.0124, 0.0000, 0.0000, 0.0133,\n",
       "        0.0158, 0.0176, 0.0121, 0.0000, 0.0000, 0.0000, 0.0147, 0.0000, 0.0106,\n",
       "        0.0000, 0.0119, 0.0000, 0.0008, 0.0043, 0.0134, 0.0075, 0.0000, 0.0000,\n",
       "        0.0172, 0.0000, 0.0052, 0.0000, 0.0171, 0.0000, 0.0024, 0.0090, 0.0011,\n",
       "        0.0000, 0.0000, 0.0000, 0.0111, 0.0055, 0.0143, 0.0035, 0.0000, 0.0045,\n",
       "        0.0099]),\n",
       "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_1.forward(train_input.narrow(0, 1, mini_batch_size))\n",
    "pred = output.max(1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monthly-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2699],\n",
      "        [0.1921],\n",
      "        [0.2592],\n",
      "        [0.2486],\n",
      "        [0.1133],\n",
      "        [0.2062],\n",
      "        [0.0203],\n",
      "        [0.2563],\n",
      "        [0.2516]]) ok tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model = model_1\n",
    "model.reset_params()\n",
    "output = model.forward(train_input.narrow(0, 1, mini_batch_size))\n",
    "print(output[1:10], 'ok', train_target.narrow(0, 1, mini_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-director",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-pitch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-forth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "potential-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_1(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    nb_epochs = 250\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "boxed-utilization",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-bbc19f392405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain_model_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# issue is that I put the model_1 output_hidden as 1 instead of 2..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# train_model(model_1, train_input, train_target.reshape(train_target.size(0),1), nb_epochs, mini_batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-aef2526cfc4d>\u001b[0m in \u001b[0;36mtrain_model_1\u001b[1;34m(model, train_input, train_target)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m-> 1048\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2386\u001b[0m         )\n\u001b[0;32m   2387\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2388\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2389\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 1 is out of bounds."
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "def create_shallow_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 25),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(25, 25),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(25, 1)\n",
    "    )\n",
    "\n",
    "mini_batch_size = 100\n",
    "train_target_one_hot = one_hot(train_target)\n",
    "\n",
    "model_1 = create_shallow_model()\n",
    "\n",
    "for i in range(100):\n",
    "    train_model_1(model_1, train_input, train_target)\n",
    "    # issue is that I put the model_1 output_hidden as 1 instead of 2.. \n",
    "    # train_model(model_1, train_input, train_target.reshape(train_target.size(0),1), nb_epochs, mini_batch_size)\n",
    "    print(\"Train accuracy: \", round(compute_accuracy(model_1, train_input, train_target, mini_batch_size), 2))\n",
    "    print(\"Test accuracy:\", round(compute_accuracy(model_1, test_input, test_target, mini_batch_size), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "designed-nickel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-character",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-thermal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-catalyst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-socket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-geography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "macro-hollywood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.narrow(0, 1, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "speaking-reaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*(model.forward(train_input.narrow(0, 1, mini_batch_size)) - train_target.narrow(0, 1, mini_batch_size).reshape(100,1))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "expanded-malta",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0427],\n",
       "        [0.0049],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0128],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0395],\n",
       "        [0.0420],\n",
       "        [0.0249],\n",
       "        [0.0000],\n",
       "        [0.0429],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0274],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0081],\n",
       "        [0.0454],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0377],\n",
       "        [0.0164],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0419],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0312],\n",
       "        [0.0000],\n",
       "        [0.0354],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0335],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0244],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0695],\n",
       "        [0.0385],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0179],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0293],\n",
       "        [0.0014],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0249],\n",
       "        [0.0250],\n",
       "        [0.0377],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0046],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0272],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0133],\n",
       "        [0.0000],\n",
       "        [0.0165],\n",
       "        [0.0612],\n",
       "        [0.0000],\n",
       "        [0.0557],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0247]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(train_input.narrow(0, 1, mini_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "exotic-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.narrow(0, 1, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "guilty-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "        [ 0.0854,  0.0854, -1.9146,  ..., -1.9146, -1.9146, -1.9146],\n",
       "        [ 0.0097,  0.0097, -1.9903,  ..., -1.9903, -1.9903, -1.9903],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "        [ 0.0000,  0.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "        [ 0.0493,  0.0493, -1.9507,  ..., -1.9507, -1.9507, -1.9507]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(model.forward(train_input.narrow(0, 1, mini_batch_size)) - train_target.narrow(0, 1, mini_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-things",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-language",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-sauce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-answer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
